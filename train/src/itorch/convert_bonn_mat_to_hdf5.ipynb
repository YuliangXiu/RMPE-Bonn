{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "from numpy.core.records import fromarrays\n",
    "from itertools import compress\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os, pprint\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/yuliang/data/MultiPerson_PoseTrack_v0.1/videos_align\"\n",
    "mat_path = \"/home/yuliang/data/MultiPerson_PoseTrack_v0.1/MultiPerson_PoseTrack_v0.1.mat\"\n",
    "bonn_mat = loadmat(mat_path)['RELEASE']\n",
    "is_train = bonn_mat['is_train'][0,0]\n",
    "\n",
    "video_names = [video_name[0][0] for video_name in bonn_mat['annolist'][0,0]['name']]\n",
    "for idx,video_name in enumerate(video_names):\n",
    "    if len(video_name) == 6:\n",
    "        video_names[idx] = '000'+video_name\n",
    "\n",
    "video_frames = [video_frame[0][0] for video_frame in bonn_mat['annolist'][0,0]['num_frames']]\n",
    "video_persons = [video_frame[0][0] for video_frame in bonn_mat['annolist'][0,0]['num_persons']]\n",
    "\n",
    "train_names = list(compress(video_names[:], is_train))\n",
    "test_names = [x for x in video_names if x not in train_names]\n",
    "\n",
    "train_frames = list(compress(video_frames[:], is_train))\n",
    "test_frames = list(compress(video_frames[:], 1-is_train))\n",
    "\n",
    "train_persons = list(compress(video_persons[:], is_train))\n",
    "test_persons = list(compress(video_persons[:], 1-is_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print video_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.array([i[0][0] for i in bonn_mat['annolist'][0][0]['annopoints'][0][0][0][0][0][0]['point']['id'][0]])\n",
    "print(bonn_mat['annolist'][0][0]['annopoints'][1][0].shape)\n",
    "print 'point' in bonn_mat['annolist'][0][0]['annopoints'][9][0][3][0][0].dtype.fields.keys()\n",
    "print len(bonn_mat['annolist'][0][0]['annopoints'][9][0][4][0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_ascii(text):\n",
    "    return np.array([ord(char) for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print convert_to_ascii(data['image_id'][1])\n",
    "# print list(set([0,1,2,3,4,5,8,9,10,11,12,13,14,15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot = {'visible':[], 'imgname':[],'part':[],'bndbox':[]}\n",
    "full_ids = set([0,1,2,3,4,5,8,9,10,11,12,13,14,15])\n",
    "\n",
    "for vid, vname in enumerate(tqdm_notebook(video_names)):\n",
    "    for fid in xrange(video_frames[vid]):\n",
    "        fname = '{:0>5}.jpg'.format(fid+1)\n",
    "        imgname = os.path.join(vname,fname)\n",
    "        img_height, img_width, _ = cv.imread(os.path.join(root_dir,imgname)).shape\n",
    "#         img_height -= 2\n",
    "#         img_width -= 2\n",
    "        for pid in xrange(video_persons[vid]):\n",
    "            if (len(bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0]) == 0) or \\\n",
    "               ('point' not in bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0].dtype.fields.keys()):\n",
    "                continue\n",
    "            xmin = np.min(bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0][0]['point']['x'][0])[0][0]\n",
    "            ymin = np.min(bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0][0]['point']['y'][0])[0][0]\n",
    "            xmax = np.max(bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0][0]['point']['x'][0])[0][0]\n",
    "            ymax = np.max(bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0][0]['point']['y'][0])[0][0]\n",
    "            if xmin>=xmax or ymin>=ymax:\n",
    "                continue\n",
    "#                 print 'error max min: {} {} {} {}'.format(xmin, ymin, xmax, ymax)\n",
    "#                 print bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0][0]['point']['x'][0]\n",
    "#                 print bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0][0]['point']['y'][0]\n",
    "#                 continue\n",
    "#             print xmin, ymin, xmax, ymax\n",
    "            width, height = xmax-xmin, ymax-ymin\n",
    "            ratio = 0.05\n",
    "            bndbox = np.array([np.max([np.min([xmin-width*ratio,img_width]),1]), np.max([np.min([ymin-height*ratio,img_height]),1]),\\\n",
    "                               np.max([np.min([xmax+width*ratio,img_width]),1]), np.max([np.min([ymax+height*ratio,img_height]),1])])\n",
    "            visible = np.array([i[0][0] for i in bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0][0]['point']['is_visible'][0]])\n",
    "            part_x = np.array([i[0][0] for i in bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0][0]['point']['x'][0]])\n",
    "            part_y = np.array([i[0][0] for i in bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0][0]['point']['y'][0]])\n",
    "            part_x[part_x>img_width] = img_width\n",
    "            part_y[part_y>img_height] = img_height\n",
    "            \n",
    "#             part_x[part_x==0] = 1\n",
    "#             part_y[part_y==0] = 1\n",
    "            \n",
    "            if np.ceil(bndbox[0])>img_width or np.ceil(bndbox[1])>img_height or np.ceil(bndbox[2])>img_width or np.ceil(bndbox[3])>img_height or (0 in np.ceil(bndbox))\\\n",
    "                    or np.ceil(bndbox[0])>=np.ceil(bndbox[2]) or np.ceil(bndbox[1])>=np.ceil(bndbox[3]):\n",
    "                continue\n",
    "#                 print 'error bndbox'\n",
    "#             if np.max(part_x)>img_width or np.max(part_y)>img_height or np.min(part_x)<=0 or np.min(part_y)<=0:\n",
    "#                 print 'error part'\n",
    "            ids = set([i[0][0] for i in bonn_mat['annolist'][0][0]['annopoints'][vid][0][pid][fid][0][0]['point']['id'][0]])\n",
    "            miss_ids = [list(full_ids).index(i) for i in (full_ids-ids)]\n",
    "            for miss_id in sorted(miss_ids):\n",
    "                visible = np.insert(visible, miss_id, 0)\n",
    "                part_x = np.insert(part_x, miss_id, 0.0)\n",
    "                part_y = np.insert(part_y, miss_id, 0.0)\n",
    "                \n",
    "            part = np.stack((part_x, part_y), axis=1)\n",
    "#             print imgname\n",
    "            annot['imgname'] += [convert_to_ascii(imgname)]\n",
    "            annot['bndbox'] += [np.ceil(bndbox.reshape(1,4))]\n",
    "            annot['visible'] += [visible.reshape(1,14)]\n",
    "            annot['part'] += [part.reshape(14,2).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1.2,3,4,5,9.23])\n",
    "print np.ceil(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1000):\n",
    "    print \"\".join([chr(i) for i in annot['imgname'][k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/home/yuliang/code/multi-human-pose/train/data/bonn-train/annot.h5','w') as f:\n",
    "    f.attrs['name'] = 'bonn-train'\n",
    "    for k in annot.keys():\n",
    "        f[k] = np.array(annot[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(\"/home/yuliang/code/multi-human-pose/train/data/bonn-train/images/000000010/00000.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(annot['imgname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/home/yuliang/code/multi-human-pose/train/data/mpii-box/annot.h5','r') as f:\n",
    "    id = 2\n",
    "    print f['bndbox'][id]\n",
    "    print f['part'][id]\n",
    "    print \"\".join([chr(int(c)) for c in f['imgname'][id]])\n",
    "    print len(f['bndbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/home/yuliang/code/multi-human-pose/train/data/bonn-train/annot.h5','r') as f:\n",
    "    id = 10\n",
    "    print f['bndbox'][id]\n",
    "    print f['part'][id]\n",
    "    print \"\".join([chr(c) for c in f['imgname'][id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/home/yuliang/code/multi-human-pose/train/data/ai-cha/annot.h5','r') as f:\n",
    "    print f['bndbox'][1]\n",
    "    print f['part'][1]\n",
    "    print len(f['bndbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('/home/yuliang/data/MultiPerson_PoseTrack_v0.1/videos/000001/00002.jpg')\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
