{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert RMPE results(.txt) into python struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "from numpy.core.records import fromarrays\n",
    "from itertools import compress\n",
    "import os, pprint\n",
    "\n",
    "\n",
    "pt_pred_mat_path = '/home/yuliang/code/PoseTrack-CVPR2017/data/bonn-multiperson-posetrack/results/exp3/pred_annolist.mat'\n",
    "rmpe_pred_dir = '/home/yuliang/code/multi-human-pose/predict/NMS'\n",
    "\n",
    "pt_pred_mat = loadmat(pt_pred_mat_path)\n",
    "rmpe_img_box_idx = np.loadtxt('index.txt', delimiter=' ', dtype='S20,i4,i4')\n",
    "rmpe_box_score = np.loadtxt('scores-proposals.txt', dtype='d')\n",
    "rmpe_box_pose_scores = np.loadtxt('scores.txt', dtype='S20'+16*',d')\n",
    "rmpe_box_pose_pos = np.loadtxt('pred.txt', dtype='S20'+32*',i4')\n",
    "\n",
    "rmpe_results = dict()\n",
    "\n",
    "root_dir = \"/home/yuliang/data/MultiPerson_PoseTrack_v0.1/\"\n",
    "video_dir = os.path.join(root_dir,'videos')\n",
    "mat_path = \"/home/yuliang/data/MultiPerson_PoseTrack_v0.1/MultiPerson_PoseTrack_v0.1.mat\"\n",
    "rmpe_mat_path = '/home/yuliang/code/PoseTrack-CVPR2017/data/bonn-multiperson-posetrack/results/exp3/rmpe_results.mat'\n",
    "bonn_mat = loadmat(mat_path)['RELEASE']\n",
    "is_train = bonn_mat['is_train'][0,0]\n",
    "\n",
    "video_names = [video_name[0][0] for video_name in bonn_mat['annolist'][0,0]['name']]\n",
    "video_frames = [video_frame[0][0] for video_frame in bonn_mat['annolist'][0,0]['num_frames']]\n",
    "\n",
    "train_names = list(compress(video_names[:], is_train))\n",
    "test_names = [x for x in video_names if x not in train_names]\n",
    "\n",
    "train_frames = list(compress(video_frames[:], is_train))\n",
    "test_frames = list(compress(video_frames[:], 1-is_train))\n",
    "\n",
    "\n",
    "for idx, test_name in enumerate(test_names):\n",
    "    rmpe_results[test_name] = {}\n",
    "    rmpe_results[test_name]['num_frames'] = test_frames[idx]\n",
    "    for frame in range(1, test_frames[idx]+1):\n",
    "        frame_name = '{:0>5}.jpg'.format(frame)\n",
    "        rmpe_results[test_name][frame_name] = {}\n",
    "\n",
    "for idx, item in enumerate(rmpe_img_box_idx):\n",
    "    video_id, frame_id = item[0].split('/')[0], item[0].split('/')[1]\n",
    "    rmpe_results[video_id][frame_id]['img_path'] = os.path.join(video_dir,item[0])\n",
    "    for idx in range(1, item[2]-item[1]+2):\n",
    "        rmpe_results[video_id][frame_id][idx] = {}\n",
    "    rmpe_results[video_id][frame_id]['num_boxes'] = item[2]-item[1]+1\n",
    "    \n",
    "    \n",
    "for idx, test_name in enumerate(test_names):\n",
    "    max_box = 0\n",
    "    for frame in range(1, test_frames[idx]+1):\n",
    "        frame_name = '{:0>5}.jpg'.format(frame)\n",
    "        if rmpe_results[test_name][frame_name]['num_boxes'] >= max_box:\n",
    "            max_box = rmpe_results[test_name][frame_name]['num_boxes']\n",
    "    rmpe_results[test_name]['num_persons'] = max_box\n",
    "        \n",
    "\n",
    "last_video_id, last_frame_id = \"\", \"\"\n",
    "box_id = 1\n",
    "for idx, item in enumerate(rmpe_box_pose_pos):\n",
    "    video_id, frame_id = item[0].split('/')[0], item[0].split('/')[1]\n",
    "    if video_id == last_video_id and frame_id == last_frame_id:\n",
    "        box_id += 1\n",
    "    else:\n",
    "        box_id = 1\n",
    "    last_video_id, last_frame_id = video_id, frame_id\n",
    "    rmpe_results[video_id][frame_id][box_id]['box_pose_pos'] = np.asarray(item.tolist()[1:33], dtype='d').reshape(-1,2)\n",
    "    rmpe_results[video_id][frame_id][box_id]['box_pose_score'] = np.asarray(rmpe_box_pose_scores[idx].tolist()[1:17], dtype='d')\n",
    "    rmpe_results[video_id][frame_id][box_id]['box_score'] = np.mean(rmpe_results[video_id][frame_id][box_id]['box_pose_score'])\n",
    "    pose_pos = rmpe_results[video_id][frame_id][box_id]['box_pose_pos']\n",
    "    x_min, x_max, y_min, y_max = np.min(pose_pos[:,0]), np.max(pose_pos[:,0]), np.min(pose_pos[:,1]), np.max(pose_pos[:,1])\n",
    "    width, height = x_max-x_min, y_max-y_min\n",
    "    expand_ratio = 0.15\n",
    "    x_min, x_max = x_min-expand_ratio*width, x_max+expand_ratio*width\n",
    "    y_min, y_max = y_min-expand_ratio*height, y_max+expand_ratio*height\n",
    "    rmpe_results[video_id][frame_id][box_id]['box_pos'] = [x_min, x_max, y_min, y_max]\n",
    "\n",
    "# savemat(rmpe_mat_path, rmpe_results)\n",
    "\n",
    "print pt_pred_mat['annolist'][0]['num_frames'][0][0,0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_grade(l):\n",
    "    return 0.8*l[0]+0.1*l[1]+0.1*l[2]\n",
    "\n",
    "def best_matching(pid, all_cors, region_ids, frame_name, next_frame_name, cmu_video_info):\n",
    "    x1, y1, x2, y2, scores = [all_cors[:,col] for col in range(5)]\n",
    "    next_and_ids = {}\n",
    "    all_grades_details = []\n",
    "    all_grades = []\n",
    "    ratio = 0.0\n",
    "    for next_pid in range(1, cmu_video_info[next_frame_name]['num_boxes']+1):\n",
    "        next_and_ids[next_pid] = find_region_cors(cmu_video_info[next_frame_name][next_pid]['box_pos'], all_cors)\n",
    "        inter = region_ids & next_and_ids[next_pid]\n",
    "        union = region_ids | next_and_ids[next_pid]\n",
    "        ratio = len(inter)/(len(union)+0.0001)\n",
    "        box1_score, box2_score = [cmu_video_info[frame_name][pid]['box_score'], cmu_video_info[next_frame_name][next_pid]['box_score']]\n",
    "        single_grade = cal_grade([ratio, box1_score, box2_score])\n",
    "        single_grade_details = [ratio, box1_score, box2_score]\n",
    "        all_grades.append(single_grade)\n",
    "        all_grades_details.append(single_grade_details)\n",
    "    if max(all_grades) > 0.2:\n",
    "        best_match_id = all_grades.index(max(all_grades))\n",
    "        best_match_score = all_grades_details[best_match_id]\n",
    "    else:\n",
    "        best_match_id = np.nan\n",
    "        best_match_score = all_grades_details[all_grades.index(max(all_grades))]\n",
    "    return best_match_id+1, best_match_score\n",
    "\n",
    "def find_region_cors(box_pos, all_cors):\n",
    "    x1, y1, x2, y2, scores = [all_cors[:,col] for col in range(5)]\n",
    "    x_min, x_max, y_min, y_max = box_pos\n",
    "    x1_region_ids = set(np.where((x1>=x_min) & (x1<=x_max))[0].tolist())\n",
    "    y1_region_ids = set(np.where((y1>=y_min) & (y1<=y_max))[0].tolist())\n",
    "    region_ids = x1_region_ids & y1_region_ids\n",
    "    return region_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# box tracking with DeepMatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94f6398b9cc43f7ae14843f1aca5b6b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000002\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "000010\n",
      "000017\n",
      "13\n",
      "000023\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "000028\n",
      "26\n",
      "27\n",
      "000048\n",
      "000687796\n",
      "28\n",
      "29\n",
      "001374383\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "001912897\n",
      "002619671\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "004389994\n",
      "008413996\n",
      "035647817\n",
      "038185763\n",
      "38\n",
      "047298377\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "047445318\n",
      "047935229\n",
      "048242360\n",
      "048759844\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "048766707\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "049303512\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "049888815\n",
      "71\n",
      "060470979\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "078963625\n",
      "81\n",
      "82\n",
      "83\n",
      "089204656\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "090932040\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "093910870\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "098484120\n",
      "122\n",
      "098563362\n",
      "099273730\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "dm_dir = '/home/yuliang/code/PoseTrack-CVPR2017/data/bonn-multiperson-posetrack/correspondences'\n",
    "dm_results = dict()\n",
    "\n",
    "for vid, video_name in enumerate(tqdm_notebook(test_names)):\n",
    "    print video_name\n",
    "    dm_results[video_name] = {}\n",
    "    for frame in range(1, test_frames[vid]):\n",
    "        \n",
    "        next_frame = frame + 1\n",
    "        frame_id = '{:0>5}'.format(frame)\n",
    "        frame_name = '{:0>5}.jpg'.format(frame)\n",
    "        next_frame_id = '{:0>5}'.format(next_frame)\n",
    "        next_frame_name = '{:0>5}.jpg'.format(next_frame)\n",
    "        \n",
    "        max_pid_id = 0\n",
    "        \n",
    "        all_cors = np.loadtxt(os.path.join(dm_dir,video_name,\"\".join([frame_id,'_',next_frame_id,'.txt'])))\n",
    "        dm_results[video_name][frame_name] = all_cors\n",
    "        \n",
    "        for pid in range(1, rmpe_results[video_name][frame_name]['num_boxes']+1):\n",
    "            if rmpe_results[video_name][frame_name][pid] != []:\n",
    "                if frame ==1:\n",
    "                    rmpe_results[video_name][frame_name][pid]['new_pid'] = pid\n",
    "                    rmpe_results[video_name][frame_name][pid]['match_score'] = 0\n",
    "                box_pos = rmpe_results[video_name][frame_name][pid]['box_pos']\n",
    "                region_ids = find_region_cors(box_pos, all_cors)\n",
    "                best_match_pid, match_score = best_matching(pid, all_cors, region_ids, frame_name, next_frame_name, rmpe_results[video_name])\n",
    "#                 rmpe_results[video_name][frame_name][pid]['match_score'] = match_score\n",
    "                \n",
    "                if not np.isnan(best_match_pid):\n",
    "                    if ('match_score' not in rmpe_results[video_name][next_frame_name][best_match_pid]) or \\\n",
    "                (cal_grade(match_score) > cal_grade(rmpe_results[video_name][next_frame_name][best_match_pid]['match_score'])):\n",
    "                        rmpe_results[video_name][next_frame_name][best_match_pid]['match_score'] = match_score\n",
    "                        last_frame_related_id = rmpe_results[video_name][frame_name][pid]['new_pid']\n",
    "                        rmpe_results[video_name][next_frame_name][best_match_pid]['new_pid'] = last_frame_related_id\n",
    "                        if last_frame_related_id > max_pid_id:\n",
    "                            max_pid_id = last_frame_related_id\n",
    "                    \n",
    "        for next_pid in range(1, rmpe_results[video_name][next_frame_name]['num_boxes']+1):\n",
    "            if 'new_pid' not in rmpe_results[video_name][next_frame_name][next_pid]:\n",
    "                max_pid_id += 1\n",
    "                rmpe_results[video_name][next_frame_name][next_pid]['new_pid'] = max_pid_id \n",
    "                rmpe_results[video_name][next_frame_name][next_pid]['match_score'] = 0\n",
    "        \n",
    "#         for pid in range(1, rmpe_results[video_name][frame_name]['num_boxes']+1):\n",
    "#             if rmpe_results[video_name][frame_name][pid] != []:\n",
    "#                 if frame ==1:\n",
    "#                     rmpe_results[video_name][frame_name][pid]['new_pid'] = pid\n",
    "#                 box_pos = rmpe_results[video_name][frame_name][pid]['box_pos']\n",
    "#                 region_ids = find_region_cors(box_pos, all_cors)\n",
    "#                 best_match_pid, match_score = best_matching(pid, all_cors, region_ids, frame_name, next_frame_name, rmpe_results[video_name])\n",
    "#                 rmpe_results[video_name][frame_name][pid]['match_score'] = match_score\n",
    "#                 if not np.isnan(best_match_pid):\n",
    "#                     last_frame_related_id = rmpe_results[video_name][frame_name][pid]['new_pid']\n",
    "#                     rmpe_results[video_name][next_frame_name][best_match_pid]['new_pid'] = last_frame_related_id\n",
    "#                     if last_frame_related_id > max_pid_id:\n",
    "#                         max_pid_id = last_frame_related_id\n",
    "#         for next_pid in range(1, rmpe_results[video_name][next_frame_name]['num_boxes']+1):\n",
    "#             if 'new_pid' not in rmpe_results[video_name][next_frame_name][next_pid]:\n",
    "#                 max_pid_id += 1\n",
    "#                 rmpe_results[video_name][next_frame_name][next_pid]['new_pid'] = max_pid_id \n",
    "#         if next_frame == test_frames[vid]:\n",
    "#             for pid in range(1, rmpe_results[video_name][next_frame_name]['num_boxes']+1):\n",
    "#                 rmpe_results[video_name][next_frame_name][pid]['match_score'] = 0\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdec41e571ba4f59b67ae956a385d2bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000002\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-19173705f95e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mbox_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmpe_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'box_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mall_cors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdm_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_frame_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mregion_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_region_cors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_cors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mbest_match_pid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_matching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_cors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_frame_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmpe_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuliang/.pyenv/versions/2.7.13/envs/env2.7/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuliang/.pyenv/versions/2.7.13/envs/env2.7/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfloatconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34mb'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dm_dir = '/home/yuliang/code/PoseTrack-CVPR2017/data/bonn-multiperson-posetrack/correspondences'\n",
    "dm_results = dict()\n",
    "\n",
    "\n",
    "for vid, video_name in enumerate(tqdm_notebook(test_names)):\n",
    "    close_frames = 3\n",
    "    dm_results[video_name] = {}\n",
    "    max_pid_id = 0\n",
    "\n",
    "    print video_name\n",
    "    \n",
    "    for frame in range(1, test_frames[vid]):\n",
    "        frame_id = '{:0>5}'.format(frame)\n",
    "        frame_name = '{:0>5}.jpg'.format(frame)\n",
    "                \n",
    "        if frame == test_frames[vid]-(close_frames-1):\n",
    "            close_frames = close_frames-1\n",
    "        \n",
    "        for next_n in range(1, close_frames+1):\n",
    "            next_frame = frame + next_n\n",
    "            next_frame_id = '{:0>5}'.format(next_frame)\n",
    "            next_frame_name = '{:0>5}.jpg'.format(next_frame)\n",
    "        \n",
    "            for pid in range(1, rmpe_results[video_name][frame_name]['num_boxes']+1):\n",
    "                if frame ==1:\n",
    "                    rmpe_results[video_name][frame_name][pid]['new_pid'] = pid\n",
    "                    rmpe_results[video_name][frame_name][pid]['match_score'] = 0\n",
    "\n",
    "                box_pos = rmpe_results[video_name][frame_name][pid]['box_pos']\n",
    "                all_cors = np.loadtxt(os.path.join(dm_dir,video_name,\"\".join([frame_id,'_',next_frame_id,'.txt'])))\n",
    "                region_ids = find_region_cors(box_pos, all_cors)\n",
    "                best_match_pid, match_score = best_matching(pid, all_cors, region_ids, frame_name, next_frame_name, rmpe_results[video_name])\n",
    "\n",
    "                if not np.isnan(best_match_pid):\n",
    "                    if ('match_score' not in rmpe_results[video_name][next_frame_name][best_match_pid]) or \\\n",
    "                (cal_grade(match_score) > cal_grade(rmpe_results[video_name][next_frame_name][best_match_pid]['match_score'])):\n",
    "                        rmpe_results[video_name][next_frame_name][best_match_pid]['match_score'] = match_score\n",
    "                        last_frame_related_id = rmpe_results[video_name][frame_name][pid]['new_pid']\n",
    "                        rmpe_results[video_name][next_frame_name][best_match_pid]['new_pid'] = last_frame_related_id\n",
    "                        if last_frame_related_id > max_pid_id:\n",
    "                            max_pid_id = last_frame_related_id\n",
    "\n",
    "        next_frame = frame + 1\n",
    "        next_frame_name = '{:0>5}.jpg'.format(next_frame)\n",
    "        for next_pid in range(1, rmpe_results[video_name][next_frame_name]['num_boxes']+1):\n",
    "            if 'new_pid' not in rmpe_results[video_name][next_frame_name][next_pid]:\n",
    "                max_pid_id += 1\n",
    "                rmpe_results[video_name][next_frame_name][next_pid]['new_pid'] = max_pid_id \n",
    "                rmpe_results[video_name][next_frame_name][next_pid]['match_score'] = 0\n",
    "    print max_pid_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert txt into mat file( with tracking )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafe02f416684b0887f94d60ffd6c856"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy.core.records import fromarrays\n",
    "from scipy.io import savemat\n",
    "from tqdm import tqdm_notebook\n",
    "    \n",
    "for idx, test_name in enumerate(test_names):\n",
    "    max_box = 0\n",
    "    for frame in range(1, test_frames[idx]+1):\n",
    "        frame_name = '{:0>5}.jpg'.format(frame)\n",
    "        for pid in range(1, rmpe_results[test_name][frame_name]['num_boxes']+1):\n",
    "            if rmpe_results[test_name][frame_name][pid]['new_pid'] > max_box:\n",
    "                max_box = rmpe_results[test_name][frame_name][pid]['new_pid']\n",
    "    rmpe_results[test_name]['num_persons'] = max_box\n",
    "            \n",
    "\n",
    "name1 = ['num_frames', 'name', 'num_persons', 'annopoints']\n",
    "name2 = ['x', 'y', 'is_visible', 'id']\n",
    "\n",
    "rmpe_part_ids = [0,1,2,3,4,5,10,11,12,13,14,15,8,9]\n",
    "\n",
    "rmpe_part_names = ['RAnkle','RKnee','RHip','LHip','LKnee','LAnkle','Pelv','Thrx','Neck','Head',\\\n",
    "            'RWrist','RElbow','RShoulder','LShoulder','LElbow','LWrist']\n",
    "\n",
    "pt_part_ids = [0,1,2,3,4,5,8,9,10,11,12,13,14,15]\n",
    "\n",
    "pt_part_names = ['RAnkle','RKnee','RHip','LHip','LKnee','LAnkle','RWrist','RElbow',\\\n",
    "                 'RShoulder','LShoulder','LElbow','LWrist','Neck','Head']   \n",
    "\n",
    "cmu_part_names = ['Head','Neck','RShoulder','RElbow','RWrist','LShoulder','LElbow','LWrist',\\\n",
    "                  'RHip','RKnee','RAnkle','LHip','LKnee','LAnkle','REye','LEye','REar','LEar'] \n",
    " \n",
    "\n",
    "num_frames = [num[0][0][0] for num in gt_mat['annolist']['num_frames']]\n",
    "name = test_names\n",
    "num_persons = [rmpe_results[vid]['num_persons'] for vid in test_names]\n",
    "annopoints = [np.empty(pair, dtype=np.object) for pair in zip(num_persons, num_frames)]\n",
    "\n",
    "for vid in tqdm_notebook(range(len(annopoints))):\n",
    "    pn, fn = annopoints[vid].shape\n",
    "    for fid in range(1,fn+1):\n",
    "        frame_name = '{:0>5}.jpg'.format(fid)\n",
    "        for pid in range(1, pn+1):\n",
    "            if pid <= rmpe_results[name[vid]][frame_name]['num_boxes']:\n",
    "                x = rmpe_results[name[vid]][frame_name][pid]['box_pose_pos'][rmpe_part_ids,0]\n",
    "                y = rmpe_results[name[vid]][frame_name][pid]['box_pose_pos'][rmpe_part_ids,1]\n",
    "                new_pid = rmpe_results[name[vid]][frame_name][pid]['new_pid']\n",
    "                is_visible = np.ones((len(y)))\n",
    "                ids = rmpe_part_ids\n",
    "                c_len = 5\n",
    "                contents = np.empty([c_len,], dtype=object)\n",
    "                for i in range(c_len):\n",
    "                    contents[i] = np.empty([1,1], dtype=object)\n",
    "                contents[0][0,0] = fromarrays([x, y, is_visible, ids], names=name2)\n",
    "                contents[1][0,0] = rmpe_results[name[vid]][frame_name][pid]['box_score']\n",
    "                contents[2][0,0] = rmpe_results[name[vid]][frame_name][pid]['box_pos']\n",
    "                contents[3][0,0] = rmpe_results[name[vid]][frame_name][pid]['new_pid']\n",
    "                contents[4][0,0] = rmpe_results[name[vid]][frame_name][pid]['match_score']\n",
    "                annopoints[vid][new_pid-1,fid-1] = fromarrays([contents[0], contents[1], contents[2], contents[3], contents[4]], \\\n",
    "                                                          names=['point','box_score','box_pos','new_pid','match_score'],\\\n",
    "                                                          formats=['O', 'O', 'O', 'O', 'O'])\n",
    "            else:\n",
    "                for pid in range(1, pn+1):\n",
    "                    if type(annopoints[vid][pid-1,fid-1]) is not np.recarray:\n",
    "                        annopoints[vid][pid-1, fid-1] = []\n",
    "\n",
    "myrec = fromarrays([num_frames, name, num_persons, annopoints], names=name1)\n",
    "savemat(rmpe_mat_path, {'annolist': myrec})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_mat = loadmat('/home/yuliang/code/PoseTrack-CVPR2017/data/bonn-multiperson-posetrack/annolist/test/annolist.mat')\n",
    "posetrack_mat = loadmat('/home/yuliang/code/PoseTrack-CVPR2017/data/bonn-multiperson-posetrack/results/exp3/pred_annolist.mat')\n",
    "rmpe_mat = loadmat('/home/yuliang/code/PoseTrack-CVPR2017/data/bonn-multiperson-posetrack/results/exp3/rmpe_results.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth tracking numbers:\n",
      "[4, 3, 6, 2, 5, 3, 7, 8, 3, 5, 3, 2, 4, 10, 6, 5, 2, 13, 4, 10, 4, 3, 4, 11, 16, 14, 8, 8, 5, 5] <type 'list'>\n",
      "posetrack tracking numbers:\n",
      "[8] <type 'list'>\n",
      "posetrack-groundtruth diff: 109\n",
      "rmpe tracking numbers:\n",
      "[19, 8, 12, 6, 7, 3, 15, 3, 11, 13, 3, 2, 4, 20, 10, 10, 2, 29, 10, 14, 9, 6, 8, 18, 56, 54, 18, 33, 21, 16] <type 'list'>\n",
      "rmpe-groundtruth diff: 267\n"
     ]
    }
   ],
   "source": [
    "def cal_diff(l1, l2):\n",
    "    return np.sum(np.abs(np.array(l1)-np.array(l2)))\n",
    "\n",
    "print 'ground truth tracking numbers:'\n",
    "gt_num_persons = [int(item[0][0][0]) for item in gt_mat['annolist']['num_persons']]\n",
    "print gt_num_persons, type(gt_num_persons)\n",
    "print 'posetrack tracking numbers:'\n",
    "pt_num_persons = [int(item[0][0]) for item in posetrack_mat['annolist'][0]['num_persons']]\n",
    "print pt_num_persons, type(pt_num_persons)\n",
    "print 'posetrack-groundtruth diff:',cal_diff(pt_num_persons, gt_num_persons)\n",
    "print 'rmpe tracking numbers:'\n",
    "rmpe_num_persons = [int(item[0][0]) for item in rmpe_mat['annolist'][0]['num_persons']]\n",
    "print rmpe_num_persons, type(rmpe_num_persons)\n",
    "print 'rmpe-groundtruth diff:',cal_diff(rmpe_num_persons, gt_num_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
